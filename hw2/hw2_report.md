<h1 align = "center">HW 2 - Archiving the Web</h1>

<h3 align = "center">Courtney Maynard</h3>
<h3 align = "center">DATA 440, Fall 2024</h3>
<h3 align = "center">October 8th, 2024</h3>

## Q1: Collect URIs From Tweets

### Parts One and Two Code: Collecting Tweets + Extracting Links from Tweets

### Parts Three and Four Code: Resolved URIs to Final Target URI

### Commentary:

---

## Q2: Get TimeMaps for Each URI

### Code:

### Commentary:

---

## Q3: Analyze Mementos Per URI-R

### Code:

### Results:

### Commentary:
*Q: What URI-Rs had the most mementos? Did that surprise you?*

---

## Q4: Analyze Datetimes of Mementos

### Code:

### Results:

### Commentary:
*Q: What can you say about the relationship between the age of a URI-R and the number of its mementos?*

*Q: What URI-R had the oldest memento? Did that surprise you?

*Q: How many URI-Rs had an age of < 1 week, meaning that their first memento was captured the same week you collected the data?*

---

## Q5 Extra Credit: Explore Conifer and ReplayWeb.Page

### Results:


### Commentary:
*Q: Why did you choose this particular topic?*

*Q: Did you have any issues in archiving the webpages?*

*Q: Do the archived webpages look like the original webpages?*

*Q: How many URLs were archived in the WARC file? How does this compare to the number of Pages?*




