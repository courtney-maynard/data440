Short Url
Updated 04 October 2024
October 05, 2024 00:45
The eruption of artificial intelligence into our lives has been so sudden that many believe its invention can only date back at most a few years.
In reality, a researcher named John McCarthy coined the term in 1955 and introduced AI as a discipline at the Dartmouth Conference of 1956. Every advance in computer technology and, more recently, in machine learning has broadened the possibilities of AI, resulting in the sometimes useful and sometimes terrifying applications we are seeing today. In researching this very article, I asked AI to recount its own development. At the same time, armies employ it to develop autonomous machines that are not only able to kill but to decide by themselves whom to kill.
I like the description of AI as a mutation because it captures a quasi-Darwinian evolution of our human intelligence into a form of intelligence external to our brains, capable of developing ideas and making decisions by itself. In his fabulous new book “Nexus,” Yuval Noah Harari affirms that AI’s capability of “making decisions and generating ideas by itself” is what truly separates it from any previous technological revolution, such as the telegraph or the printing press.
These older inventions transformed our world, but AI stands to transform it far more profoundly, changing “the shape of armies, religions, markets, and nations.” It is no exaggeration to say that we are entering the Age of AI, or the Age of Mutation, as I like to call it.
Harari duly reminds us that the print revolution led to great scientific discoveries but also to witch hunts and religious wars, “while newspapers and radio were exploited by totalitarian regimes as well as by democracies.” Adapting to the Industrial Revolution itself led to “catastrophic experiments such as imperialism and Nazism.” The perils of the transformations potentially initiated by AI are far greater still, for it is a technology that we are in the process of losing any control over if we cannot agree on its worldwide regulation.
Our current lack of coordination comes down in part to our lack of understanding and confusion regarding what AI really is and represents. We are still working our way through it. However, it is imperative that policymakers react and understand the future implications for good and bad that this technology represents.
I like the description of AI as a mutation because it captures a quasi-Darwinian evolution of our human intelligence into a form of intelligence external to our brains.
The confusion over AI is in large part due to its invisible nature. But its potential control or takeover of our essential infrastructure, which today is overwhelmingly also digital and invisible, could be of tremendous consequence. More even than the untraceable cyberattacks used to disrupt oil production or hospital infrastructure, the risk of AI gaining control over crucial systems such as nuclear power plants or nuclear weapons themselves increases every day. When it comes to AI, we no longer know who is the enemy. Clearly, the mastery of this new technological power is what will determine the future world we live in.
Today, it is not the monopoly of one powerful country or another but rather of the individuals who developed it and who will ultimately determine whether it becomes the evil mind or the saving mind.
AI does not need fuel dug up from deep underground to run on like the engines of the Industrial Revolution; it is an invisible hand. We do not know whether it is friend or foe, and it thereby breeds great confusion and fear.
The mutation of AI will necessarily lead to a mutation of our societies and of a new world order. We do not know what shape this will take, but clearly, AI is one of the most hazardous inventions of humankind. Harari warns us: “As AI grows in power and authority, and perhaps becomes a self-interpreting holy book, so the decisions made by present-day engineers could reverberate down the ages.”
Humans are “at one and the same time both the smartest and the stupidest animals on earth. We are so smart that we can produce nuclear missiles and superintelligent algorithms. And we are so stupid that we go ahead producing these things even though we’re not sure we can control them and failing to do so could destroy us.”
In this Age of Mutation, we humans must unite and be very clear with each other and with the developers of this new technology that the time to determine whether it becomes a force allowing us to better our planet and our societies, or to destroy them, is right now.
• Hassan bin Youssef Yassin worked closely with Saudi Arabia’s petroleum ministers Abdullah Tariki and Ahmed Zaki Yamani from 1959-1967. He led the Saudi Information Office in Washington from 1972-1981 and served with the Arab League’s observer delegation to the UN from 1981-1983.
